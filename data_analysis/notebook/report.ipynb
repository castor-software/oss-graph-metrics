{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev / Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install coclust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "report_project = os.environ['REPORT_PROJECT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.lines as mlines\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fig(name):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data from spoon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def open_json(file_path):\n",
    "    datastore = {}\n",
    "    with open(file_path, 'r') as f:\n",
    "        datastore = json.load(f)\n",
    "    return datastore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fonction to get the name of a library according to its definition and the depth.\n",
    "\n",
    "> 'java.util.ArrayList', depth=2 -> 'java.util'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_to_name(library_import, depth):\n",
    "    return '.'.join(library_import.split('.')[:depth])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the mapping of imports to an ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_mapping(libraries_set, depth): # TODO : Option to keep tree structure\n",
    "    A = set(sorted([import_to_name(library_import, depth) for library_import in libraries_set]) + ['UNK'])\n",
    "    length = len(A)\n",
    "    map_dict = dict(zip(A, range(length)))\n",
    "    def mapping(import_value):\n",
    "        name = import_to_name(import_value, depth)\n",
    "        if name not in A:\n",
    "            name = 'UNK'\n",
    "        return map_dict[name]\n",
    "    return mapping, A, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 more or less equal to the library level \n",
    "data = open_json(f'{report_project}_commits.json')\n",
    "libraries_set = data['libraries_set']\n",
    "commit_info = data['commit_info']\n",
    "library_depth = 2\n",
    "mapping, mapping_elemnts, mapping_size = define_mapping(libraries_set, library_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some basic vector operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1ptvUIzzaCGC",
    "outputId": "3923b1f1-c58a-49ad-c31c-8ddbc549c6e5"
   },
   "outputs": [],
   "source": [
    "def v_sum(*v):\n",
    "    return tuple([sum(e) for e in zip(*v)])\n",
    "\n",
    "def z_k(n, *Ks):\n",
    "    z_k = [0] * n\n",
    "    for i in Ks:\n",
    "        z_k[i] = 1\n",
    "    return tuple(z_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count for every commits the number of time a library was imported in all modified files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1ptvUIzzaCGC",
    "outputId": "3923b1f1-c58a-49ad-c31c-8ddbc549c6e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = []\n",
    "\n",
    "duplicate_entries = (\n",
    "    ('Tobias Ivarsson','tobias'),\n",
    "    \n",
    ")\n",
    "\n",
    "duplicate_entries = dict([ (b,a) for (a,b) in duplicate_entries])\n",
    "author_emails = {}\n",
    "\n",
    "for sha, commit in list(commit_info.items()):\n",
    "    author_name = commit['author']['name']\n",
    "    if author_name in duplicate_entries:\n",
    "        commit['author']['name'] = duplicate_entries[author_name]\n",
    "    if commit['author']['email'] not in author_emails:\n",
    "        author_emails[commit['author']['email']] = set()\n",
    "    author_emails[commit['author']['email']] = author_emails[commit['author']['email']] | set([author_name])\n",
    "\n",
    "for sha, commit in list(commit_info.items()):\n",
    "    libraries = set()\n",
    "    c = z_k(mapping_size)\n",
    "    for file, file_info in commit['files_info'].items():\n",
    "        file_libraries = set([ mapping(lib) for lib in file_info['imports'] ])\n",
    "        libraries = libraries | file_libraries\n",
    "        c = v_sum(c, z_k(mapping_size, *file_libraries))\n",
    "    if len(libraries) > 0:\n",
    "        author_name = commit['author']['name']\n",
    "        data.append( [sha, author_name] + list(c))\n",
    "        #data.append( [sha, commit['author']['name']] + list(z_k(mapping_size, *libraries)))\n",
    "\n",
    "df = pd.DataFrame(data=data, columns=['sha', 'author', *mapping_elemnts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{ key:item for key, item in author_emails.items() if len(item)>1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total number of commit : {df.shape[0]}')\n",
    "print(f'Made by {len(set(df.author))} unique contibutors')\n",
    "print(f'Represented by {len(libraries_set)} imports')\n",
    "print(f'mapped to {len(mapping_elemnts)} imports')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sum the commits by users.\n",
    "\n",
    "**Then drop the contibutors who has modified 10 file or less. And the libraries imported less than once**\n",
    "\n",
    "Finally sort the data in row and column by the number of modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_duplicate_entry(df, *duplicate_entries):\n",
    "    for entry1, entry2 in duplicate_entries:\n",
    "        df.loc[entry1] = df.loc[entry1] + df.loc[entry2]\n",
    "        df = df.drop(entry2)\n",
    "    return df\n",
    "\n",
    "agreg = df.groupby('author').sum()\n",
    "agreg = agreg.loc[:,agreg.sum() > 1]\n",
    "#agreg = agreg.loc[agreg.sum(axis=1) > 100]\n",
    "\n",
    "#agreg = group_duplicate_entry(agreg, *duplicate_entries)\n",
    "\n",
    "agreg_sorted = agreg.loc[agreg.sum(axis=1).sort_values(ascending=False).index]\n",
    "agreg_sorted = agreg_sorted.loc[:,agreg_sorted.sum(axis=0).sort_values(ascending=False).index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(agreg.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count = max(df.index)\n",
    "f = {'index': ['mean', 'min', 'max', 'count']}\n",
    "avg_contrib = pd.DataFrame(\n",
    "    data=list(\n",
    "        zip(\n",
    "            df.loc[:,'author'],\n",
    "            [ total_count - i for i in df.index])\n",
    "        ),\n",
    "    columns=['author', 'index']\n",
    ").groupby('author').agg(f)\n",
    "avg_contrib.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libraries_info = pd.DataFrame(data=[[0,0,0]] * len(mapping_elemnts), columns=['first', 'last', 'count'])\n",
    "libraries_info.index = mapping_elemnts\n",
    "for (index, row) in df.iloc[:,2:].iterrows():\n",
    "    for lib, val in row.items():\n",
    "        if val != 0:\n",
    "            if libraries_info.loc[lib]['last'] == 0:\n",
    "                libraries_info.loc[lib]['last'] = len(df) - index\n",
    "            else:\n",
    "                libraries_info.loc[lib]['first'] = len(df) - index\n",
    "            libraries_info.loc[lib]['count'] += val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libraries_info['coef'] = np.exp(libraries_info.loc[:,'last'] / len(df) - 1) ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libraries_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(figsize=(14, 25), dpi=80)\n",
    "\n",
    "#for i, row in libraries_info.sort_values('last').iterrows():\n",
    "#    color = 'r'\n",
    "#    ax.hlines(i, xmin=row['first'], xmax=row['last'], color=color)\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance between libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libraries = list(agreg_sorted.columns)\n",
    "#libraries.sort()\n",
    "librariy_trees = {}\n",
    "def import_similarity(lib_A, lib_B):\n",
    "    nodes_A = lib_A.split('.')\n",
    "    nodes_B = lib_B.split('.')\n",
    "    n = 0\n",
    "    for node_A, node_B in zip(nodes_A, nodes_B):\n",
    "        if node_A == node_B:\n",
    "            n+=1\n",
    "        else:\n",
    "            break\n",
    "    return n / library_depth\n",
    "\n",
    "libraries_distance = pd.DataFrame(list(map(lambda x: list(map(lambda y: import_similarity(x,y), libraries)), libraries)), index=libraries, columns=libraries)\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(libraries_distance)\n",
    "plt.plot()\n",
    "#for library in libraries:\n",
    "#    nodes = library.split('.')\n",
    "#    tree = librariy_trees\n",
    "#    for node in nodes:\n",
    "#        if node not in tree:\n",
    "#            tree[node] = {}\n",
    "#        tree = tree[node]\n",
    "#print(librariy_trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5), dpi=160, facecolor='w', edgecolor='k')\n",
    "number_of_contibs = agreg_sorted.sum(axis=1)\n",
    "ax = number_of_contibs.plot.bar()\n",
    "ax.set_yscale('log')\n",
    "plt.xticks(range(len(list(number_of_contibs.index))), list(number_of_contibs.index), rotation=90, fontsize=9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 15), dpi=160, facecolor='w', edgecolor='k')\n",
    "number_of_imports = agreg_sorted.sum(axis=0)\n",
    "ax = number_of_imports.plot.barh()\n",
    "ax.set_xscale('log')\n",
    "plt.yticks(range(len(list(number_of_imports.index))), list(number_of_imports.index), fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix(df, title, xlabel = '', ylabel='', log_scale=False, figsize=(18, 8)):\n",
    "    fig = plt.figure(figsize=figsize, dpi=160, facecolor='w', edgecolor='k')\n",
    "    if log_scale:\n",
    "        sns.heatmap(np.log10(df.add(1)))\n",
    "    else:\n",
    "        sns.heatmap(df)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xticks(range(len(list(df.columns))), list(df.columns), rotation=90, fontsize=9)\n",
    "    plt.yticks(range(len(list(df.index))), list(df.index), fontsize=9)\n",
    "    plt.title(title, fontsize=24)\n",
    "    #plt.ylabel('some numbers')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_matrix(agreg, 'Number of contributions (log scale)', xlabel='Import (depth=2)', ylabel='Developer', log_scale=True)\n",
    "save_fig('author_lib_random')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_matrix(agreg_sorted, 'Number of contributions (log scale)', xlabel='Import (depth=2)', ylabel='Developer', log_scale=True)\n",
    "save_fig('author_lib_ordered')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_libcontrib_totcontrib = agreg_sorted.div(agreg_sorted.sum(axis=1), axis = 0)\n",
    "plot_matrix(ratio_libcontrib_totcontrib, 'number of contributions / total contibution by author', xlabel='Library', ylabel='Dev')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_matrix(agreg_sorted.div(agreg_sorted.sum(axis=0), axis = 1), 'number of contributions / total contibution by library', xlabel='Library', ylabel='Dev')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "\n",
    "fig = plt.figure(figsize=(14, 8), dpi=160, facecolor='w', edgecolor='k')\n",
    "#agreg_sorted.apply(lambda ligne: entropy(list(ligne.map(lambda x : int(x>=1))), 0).plot.bar()\n",
    "agreg_sorted.apply(lambda ligne: entropy(list(ligne)), 0).iloc[:77].plot.bar()\n",
    "plt.title('Entropy for libraries (column) (75 most used)', fontsize=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some libraries seam to contain more information than others, such as spoon.Launcher, junit.testing, org.xml, spoon.metatmodel, spoon.patttern, java.rmi, spoon.refactoring and spoon.eclipse.\n",
    "\n",
    "Mostly it is spoon.* imports or testing import.\n",
    "\n",
    "spoon.Spoon has been imported by very few users. Infact this must be a former package that has disappeared since then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agreg_sorted['spoon.Spoon'].sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25, 12), dpi=160, facecolor='w', edgecolor='k')\n",
    "# agreg_sorted.apply(lambda ligne: entropy(list(ligne.map(lambda x : int(x>=1)))), 1).plot.bar()\n",
    "agreg_sorted.apply(lambda ligne: entropy(list(ligne)), 1).plot.bar()\n",
    "plt.title('Entropy for Authors (lines)', fontsize=24)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Who is renaud and what is spoon.Spoon ? \n",
    "And who is Jon ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "def draw_vector(v0, v1, annotation='', ax=None):\n",
    "    ax = ax or plt.gca()\n",
    "    arrowprops=dict(arrowstyle='<-',\n",
    "                    linewidth=1,\n",
    "                    shrinkA=0, shrinkB=0, color='black')\n",
    "    ax.annotate(annotation, v0, v1, arrowprops=arrowprops)\n",
    "\n",
    "def plot_pca(ax, df, pc1, pc2, pc3=None, labels=False, c=None, cmap='gnuplot', axis=None):\n",
    "    if pc3 != None:\n",
    "        scatter = ax.scatter(df.iloc[:,pc1], df.iloc[:,pc2], df.iloc[:,pc3], cmap=cmap, c=c)\n",
    "    else:\n",
    "        scatter = ax.scatter(df.iloc[:,pc1], df.iloc[:,pc2], cmap=cmap, c=c)\n",
    "        if axis is not None:\n",
    "            for (index, row) in axis.iterrows():\n",
    "                draw_vector((0,0), (row.iloc[pc1], row.iloc[pc2]), index, ax=ax)\n",
    "    if labels:\n",
    "        for index, line in df.iterrows():\n",
    "            if pc3 != None:\n",
    "                ax.text(line.iloc[pc1], line.iloc[pc2], line.iloc[pc3], f'---{index}', fontsize=4)\n",
    "            else:\n",
    "                ax.text(line.iloc[pc1], line.iloc[pc2], f'---{index}', fontsize=4)\n",
    "    ax.set_xlabel(f'PC{pc1+1}')\n",
    "    ax.set_ylabel(f'PC{pc2+1}')\n",
    "    if pc3 != None:\n",
    "        ax.set_zlabel(f'PC{pc3+1}')\n",
    "    return scatter\n",
    "\n",
    "def quick_pca_plot(df, pc1, pc2, pc3=None, labels=False, c=None, cmap='gnuplot', axis=None):\n",
    "    if pc3 != None:\n",
    "        fig = plt.figure(figsize=(8, 6), dpi=160, constrained_layout=True)\n",
    "        gs = GridSpec(2, 2, figure=fig)\n",
    "        ax12 = fig.add_subplot(gs[0, 0])\n",
    "        ax23 = fig.add_subplot(gs[0, 1])\n",
    "        ax13 = fig.add_subplot(gs[1, 0])\n",
    "        ax = fig.add_subplot(gs[1, 1], projection='3d')\n",
    "        scatter3d = plot_pca(ax, df, pc1, pc2, pc3, labels=labels, c=c, cmap=cmap)\n",
    "        plot_pca(ax12, df, pc1, pc2, labels=labels, c=c, cmap=cmap)\n",
    "        plot_pca(ax23, df, pc2, pc3, labels=labels, c=c, cmap=cmap)\n",
    "        plot_pca(ax13, df, pc1, pc3, labels=labels, c=c, cmap=cmap)\n",
    "        fig.subplots_adjust(right=0.9)\n",
    "        cbar_ax = fig.add_axes([0.95, 0.15, 0.05, 0.7])\n",
    "        if c is not None:\n",
    "            fig.colorbar(scatter3d, cax=cbar_ax)\n",
    "    else:\n",
    "        fig = plt.figure(figsize=(6, 6), dpi=160, facecolor='w', edgecolor='k')\n",
    "        ax = fig.add_subplot(111)\n",
    "        scatter = plot_pca(ax, df, pc1, pc2, labels=labels, c=c, cmap=cmap, axis=axis)\n",
    "        if c is not None:\n",
    "            plt.colorbar(scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "\n",
    "principalComponents = pca.fit_transform(agreg_sorted)\n",
    "\n",
    "principalDf = pd.DataFrame(data = principalComponents, index = ratio_libcontrib_totcontrib.index\n",
    "             , columns = ['principal component 1', 'principal component 2', 'principal component 3'])\n",
    "#quick_pca_plot(top , 0, 1, 2, labels=True, c=y_kmeans, cmap='Set1')\n",
    "quick_pca_plot(principalDf, 0, 1, pc3=2, labels=True, c=np.log10(number_of_contibs))\n",
    "save_fig('pca_raw_data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nomalisation L2\n",
    "\n",
    "Gaol : Remove the effect of size \n",
    "\n",
    "Downsides : tends to delete the effect of small libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agreg_normalized = agreg_sorted.div(np.sqrt(agreg_sorted.pow(2).sum(axis=1)), axis=0)\n",
    "plot_matrix(agreg_normalized, '', xlabel='Library', ylabel='Dev')\n",
    "save_fig('author_lib_L2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "\n",
    "principalComponents = pca.fit_transform(agreg_normalized)\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "pd.Series(np.cumsum(pca.explained_variance_ratio_)).plot.bar()\n",
    "plt.show()\n",
    "print(np.sum(pca.explained_variance_ratio_[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axis_transform = pca.transform(np.diag([1]*len(agreg_normalized.columns)))\n",
    "axis_transform_df = pd.DataFrame(data = axis_transform[:,:2], index = agreg_normalized.columns\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "quick_pca_plot(principalDf, 0, 1, labels=True, c=np.log10(number_of_contibs), axis=axis_transform_df)\n",
    "plt.show()\n",
    "\n",
    "axis_transform_df_top = axis_transform_df[np.sqrt(axis_transform_df.pow(2).sum(axis=1)) > 0.35]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "principalDf = pd.DataFrame(data = principalComponents[:,:3], index = agreg_normalized.index\n",
    "             , columns = ['principal component 1', 'principal component 2', 'principal component 3'])\n",
    "\n",
    "quick_pca_plot(principalDf, 0, 1, labels=True, c=np.log10(number_of_contibs), axis=axis_transform_df_top)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans # or GaussianMixture ? \n",
    "\n",
    "\n",
    "top = principalDf.loc[number_of_contibs > 100]\n",
    "top_agreg = agreg_normalized.loc[number_of_contibs > 100]\n",
    "\n",
    "n_clusters = 4\n",
    "colors = plt.cm.get_cmap('Set2', n_clusters)\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=100).fit(top_agreg)\n",
    "\n",
    "y_kmeans = kmeans.predict(top_agreg)\n",
    "\n",
    "quick_pca_plot(top , 0, 1, labels=True, c=y_kmeans, cmap=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_pca_plot(top , 0, 1, 2, labels=True, c=y_kmeans, cmap=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_avg_contib = avg_contrib.loc[top.index, 'index'].loc[:,'mean']\n",
    "\n",
    "quick_pca_plot(top , 0, 1, labels=True, c=top_avg_contib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_pca_plot(top, 0, 1, labels=True, c=agreg_sorted.apply(lambda ligne: entropy(list(ligne)), 1).loc[top.index])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "data = {\n",
    "    'pc1': top['principal component 1'],\n",
    "    'pc2': top['principal component 2'],\n",
    "    'avg_contib': top_avg_contib,\n",
    "    'cluster': y_kmeans,\n",
    "    'Number of commits': avg_contrib.loc[top.index, 'index'].loc[:,'count'].values\n",
    "}\n",
    "cmap = sns.cubehelix_palette(as_cmap=True)\n",
    "scatter = sns.scatterplot(x='pc1',y='pc2', data = data, hue = 'avg_contib', palette='viridis', style='cluster', size='Number of commits', sizes=(100, 400))\n",
    "center_x = -0.17\n",
    "center_y = -0.03\n",
    "for index, line in top.iterrows():\n",
    "    pos_x = line.loc['principal component 1']\n",
    "    pos_y = line.loc['principal component 2']\n",
    "    norm = np.sqrt((pos_x-center_x)**2 + (pos_y-center_y)**2)\n",
    "    offset_x = (pos_x-center_x)/norm * 0.04\n",
    "    offset_y = (pos_y-center_y)/norm * 0.04\n",
    "    offset_text_x = (pos_x-center_x)/norm * 0.0475\n",
    "    offset_text_y = (pos_y-center_y)/norm * 0.0475\n",
    "    horizontalalignment = 'center'\n",
    "    if abs(offset_y/offset_x) < 0.5:\n",
    "        horizontalalignment = 'right' if offset_x<0 else 'left'\n",
    "        offset_text_y = offset_y\n",
    "        offset_text_x = offset_x\n",
    "    text_value = f'{index}'\n",
    "    l = mlines.Line2D([pos_x,pos_x+offset_x], [pos_y,pos_y + offset_y], color='#444444')\n",
    "    scatter.add_line(l)\n",
    "    t = scatter.text(pos_x + offset_text_x, pos_y + offset_text_y, text_value, fontsize=12, va='center',horizontalalignment=horizontalalignment)\n",
    "save_fig('PCA_all')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time seems to have an influence on the results. Clearly, the red cluster at the bottom left represent the oldest contributors (who are no longer active). On the other hand, we can see that the black cluster (top right) are the recent contributors. \n",
    "\n",
    "I see two major explanations : \n",
    "- Trends during the development of the software (the team will focus on certain parts of the project over the years)\n",
    "- The packages used in the project change over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agreg_product = pd.DataFrame(np.matrix(top_agreg) * np.transpose(np.matrix(top_agreg)))\n",
    "agreg_product.index = top_agreg.index\n",
    "agreg_product.columns = top_agreg.index\n",
    "\n",
    "sns.clustermap(agreg_product)\n",
    "save_fig('similarity_clustermap')\n",
    "plt.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libraries_distance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 4\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=100).fit(top_agreg)\n",
    "y_kmeans = kmeans.predict(top_agreg)\n",
    "index_cluster = np.array(kmeans.labels_).argsort()\n",
    "\n",
    "plot_matrix(np.log(1+top_agreg.iloc[index_cluster]), title='', figsize=(18,3))\n",
    "print(top_agreg.iloc[index_cluster].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to give more weight to small packages by changing the normalization used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "top_agreg_embedded = pd.DataFrame(TSNE(n_components=2).fit_transform(agreg_normalized))\n",
    "top_agreg_embedded.index = agreg_normalized.index\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters, n_init=10, random_state=100).fit(agreg_normalized)\n",
    "\n",
    "y_kmeans = kmeans.predict(agreg_normalized)\n",
    "\n",
    "sns.scatterplot(top_agreg_embedded.iloc[:,0],top_agreg_embedded.iloc[:,1], hue=y_kmeans, palette=\"Set1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oublie exponetielle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agreg_sorted_lib_extinction = agreg_sorted.mul(libraries_info.loc[agreg_sorted.columns, 'coef'])\n",
    "agreg_sorted_lib_extinction_L2  = agreg_sorted_lib_extinction.div(np.sqrt(agreg_sorted_lib_extinction.pow(2).sum(axis=1)), axis=0)\n",
    "\n",
    "pca = PCA(n_components=2).fit_transform(agreg_sorted_lib_extinction_L2)\n",
    "\n",
    "principalDf = pd.DataFrame(data = pca, index = agreg_normalized.index\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "quick_pca_plot(principalDf, 0, 1, labels=True, c=avg_contrib.loc[principalDf.index, 'index'].loc[:,'mean'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoClust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coclust.coclustering import (CoclustMod, CoclustSpecMod, CoclustInfo)\n",
    "from coclust.visualization import plot_reorganized_matrix\n",
    "\n",
    "model = CoclustMod(n_clusters = 3, n_init = 20)\n",
    "model.fit(np.matrix(top_agreg))\n",
    "fit_data = top_agreg.iloc[np.argsort(model.row_labels_)]\n",
    "fit_data = fit_data.iloc[:, np.argsort(model.column_labels_)]\n",
    "\n",
    "plt.figure(figsize=(18,2))\n",
    "sns.heatmap(fit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
